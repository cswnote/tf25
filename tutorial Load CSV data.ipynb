{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18565c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10427bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b5e098a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\workspace\\\\Pycharm\\\\tf25'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "568d0b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.3545</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.655</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.092</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>0.2825</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   0.435     0.335   0.110         0.334          0.1355          0.0775   \n",
       "1   0.585     0.450   0.125         0.874          0.3545          0.2075   \n",
       "2   0.655     0.510   0.160         1.092          0.3960          0.2825   \n",
       "3   0.545     0.425   0.125         0.768          0.2940          0.1495   \n",
       "4   0.545     0.420   0.130         0.879          0.3740          0.1695   \n",
       "\n",
       "   Shell weight  Age  \n",
       "0        0.0965    7  \n",
       "1        0.2250    6  \n",
       "2        0.3700   14  \n",
       "3        0.2600   16  \n",
       "4        0.2300   13  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_train = pd.read_csv(\n",
    "#     path + \"/abalone/abalone_train.csv\",\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\",\n",
    "    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "           \"Viscera weight\", \"Shell weight\", \"Age\"])\n",
    "\n",
    "abalone_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67b05c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_features = abalone_train.copy()\n",
    "abalone_labels = abalone_features.pop('Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c62edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = layers.Normalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c925e64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normalize.adapt(abalone_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfc3078a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "104/104 [==============================] - 0s 542us/step - loss: 94.0048\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 523us/step - loss: 54.6768\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 549us/step - loss: 17.1702\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 525us/step - loss: 5.9953\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 526us/step - loss: 5.0830\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 529us/step - loss: 4.9694\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 526us/step - loss: 4.9238\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 542us/step - loss: 4.8951\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 518us/step - loss: 4.8792\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 513us/step - loss: 4.9249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b84b6d4ca0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_abalone_model = tf.keras.Sequential([\n",
    "    normalize,\n",
    "    layers.Dense(64),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "norm_abalone_model.compile(loss = tf.keras.losses.MeanSquaredError(),\n",
    "                           optimizer = tf.keras.optimizers.Adam())\n",
    "\n",
    "norm_abalone_model.fit(abalone_features, abalone_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "205e981d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1         1  female  38.0                   1      0  71.2833  First        C   \n",
       "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3         1  female  35.0                   1      0  53.1000  First        C   \n",
       "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.read_csv(\"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "# titanic = pd.read_csv(path + \"/titanic/train.csv\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b23b1b",
   "metadata": {},
   "source": [
    "###### Mixed Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f074ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_features = titanic.copy()\n",
    "titanic_labels = titanic_features.pop('survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f945f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None,) dtype=float32 (created by layer 'tf.__operators__.add')>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Create symbolic Input\n",
    "input = tf.keras.Input(shape=(), dtype=tf.float32)\n",
    "\n",
    "# Perform a calculation using the input\n",
    "result = 2*input + 1\n",
    "\n",
    "# the result doesn't have a value\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fc2bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc = tf.keras.Model(inputs=input, outputs=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93751087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3.0, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(calc(1))\n",
    "print(calc(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd80a8ae",
   "metadata": {},
   "source": [
    "###### make pandas datatype to dictionary of input layer of tensorflow datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8002846a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sex': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'sex')>,\n",
       " 'age': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'age')>,\n",
       " 'n_siblings_spouses': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'n_siblings_spouses')>,\n",
       " 'parch': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'parch')>,\n",
       " 'fare': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'fare')>,\n",
       " 'class': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'class')>,\n",
       " 'deck': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'deck')>,\n",
       " 'embark_town': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'embark_town')>,\n",
       " 'alone': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'alone')>}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {}\n",
    "\n",
    "for name, column in titanic_features.items():\n",
    "    dtype = column.dtype\n",
    "    if dtype == object:\n",
    "        dtype = tf.string\n",
    "    else:\n",
    "        dtype = tf.float32\n",
    "    \n",
    "    inputs[name] = tf.keras.Input(shape=(1, ), name=name, dtype=dtype)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa37f681",
   "metadata": {},
   "source": [
    "inputs(dictionary)은 titanic_features(dataframe)의 data type을 tf.dtype으로 변형한 변수\n",
    "\n",
    "dicionary & tf.dtype으로 바꾼 것은 list형태의 concatenate입력으로 사용하여 tf.layer형태로 변형하고 이것을 adapted된 normalization에 입력으로 사용하기 위해서(추정)\n",
    "concatenate의 입력은 a list of input tensors(1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a913c0",
   "metadata": {},
   "source": [
    "###### check out numeric data and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b20a0ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name=None), name='concatenate/concat:0', description=\"created by layer 'concatenate'\")\n"
     ]
    }
   ],
   "source": [
    "numeric_inputs = {name:input for name, input in inputs.items() if input.dtype == tf.float32}\n",
    "\n",
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = layers.Normalization()\n",
    "# # later, check that change titanic_feature[name] to numeric_inputs[name]\n",
    "norm.adapt(np.array(titanic_features[numeric_inputs.keys()]))\n",
    "\n",
    "all_numeric_inputs = norm(x)\n",
    "all_numeric_inputs\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "646550ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # normalize 된 tf.dtype\n",
    "preprocessed_inputs = [all_numeric_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae2859af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n",
      "class\n",
      "deck\n",
      "embark_town\n",
      "alone\n"
     ]
    }
   ],
   "source": [
    "for name, input in inputs.items():\n",
    "    if input.dtype == tf.float32:\n",
    "        continue\n",
    "    print(name)\n",
    "    # # df[name]의 단어를 lookup으로 만들고\n",
    "    lookup = layers.StringLookup(vocabulary=np.unique(titanic_features[name]))\n",
    "    # # lookup을 one-hot encoding 하는 것\n",
    "    one_hot = layers.CategoryEncoding(num_tokens=lookup.vocabulary_size())\n",
    "    \n",
    "    # # 만들어진 해당 name에 대한 lookup을 tf.dtype으로 만들어둔 inputs[name] 에 적용한 후, one_hot encodding\n",
    "    x = lookup(input)\n",
    "    x = one_hot(x)\n",
    "    \n",
    "    # # integer indices & one-hot encodding 된 tf.string형태의 layer를 추가\n",
    "    preprocessed_inputs.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f817820d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'normalization_1')>,\n",
       " <KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'category_encoding')>,\n",
       " <KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'category_encoding_1')>,\n",
       " <KerasTensor: shape=(None, 9) dtype=float32 (created by layer 'category_encoding_2')>,\n",
       " <KerasTensor: shape=(None, 5) dtype=float32 (created by layer 'category_encoding_3')>,\n",
       " <KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'category_encoding_4')>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f341c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d51e55e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 28) dtype=float32 (created by layer 'concatenate_1')>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_inputs_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4027a90",
   "metadata": {},
   "source": [
    "###### 아래 model을 만들기 위해서 위의 과정을 거침함\n",
    "titanic csv를 pd.df로 만들고 pd.df는 normal adapt, lookup의 raw data가 되게 함\n",
    "normalize는 number type의 계층 각각을 하는 것이 아니라 모아서 한번에 진행\n",
    "normalize시는 adapt된 것을 tf.dtype으로 만든 inputs의 values를 쌓아서 적용\n",
    "그리고 나서 모든 층을 concatenate 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf7491ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe52e69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model=titanic_preprocessing, rankdir='LR', dpi=150, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9aad72de",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_features_dict = {name: np.array(value) for name, value in titanic_features.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05dbb15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 28), dtype=float32, numpy=\n",
       "array([[-0.61 ,  0.395, -0.479, -0.497,  0.   ,  0.   ,  1.   ,  0.   ,\n",
       "         0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  1.   ,\n",
       "         0.   ,  0.   ,  1.   ,  0.   ]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dict = {name: value[:1] for name, value in titanic_features_dict.items()}\n",
    "titanic_preprocessing(features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb0d525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def titanic_model(preprocessing_head, inputs):\n",
    "    body = tf.keras.Sequential([\n",
    "        layers.Dense(64),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    preprocessed_inputs = preprocessing_head(inputs)\n",
    "    results = body(preprocessed_inputs)\n",
    "    model = tf.keras.Model(inputs, results)\n",
    "    \n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                 optimizer=tf.keras.optimizers.Adam())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a869664",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_model = titanic_model(titanic_preprocessing, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd3d2779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 0s 840us/step - loss: 0.6488\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 787us/step - loss: 0.5495\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 997us/step - loss: 0.4998\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 788us/step - loss: 0.4716\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 787us/step - loss: 0.4519\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 787us/step - loss: 0.4424\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 787us/step - loss: 0.4347\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 840us/step - loss: 0.4305\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 787us/step - loss: 0.4285\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 735us/step - loss: 0.4264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b84c9add00>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_model.fit(x=titanic_features_dict, y=titanic_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82c3e5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: test\\assets\n"
     ]
    }
   ],
   "source": [
    "titanic_model.save('test')\n",
    "reloaded = tf.keras.models.load_model('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5e56414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-1.745]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor([[-1.745]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "before = titanic_model(features_dict)\n",
    "after = reloaded(features_dict)\n",
    "assert (before-after)<1e-3\n",
    "print(before)\n",
    "print(after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f77b6902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def slices(features):\n",
    "    for i in itertools.count():\n",
    "        # For each feature take index `i`\n",
    "        example = {name:values[i] for name, values in features.items()}\n",
    "        yield example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2d2c650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                : male\n",
      "age                : 22.0\n",
      "n_siblings_spouses : 1\n",
      "parch              : 0\n",
      "fare               : 7.25\n",
      "class              : Third\n",
      "deck               : unknown\n",
      "embark_town        : Southampton\n",
      "alone              : n\n"
     ]
    }
   ],
   "source": [
    "for example in slices(titanic_features_dict):\n",
    "    for name, value in example.items():\n",
    "        print(f\"{name:19s}: {value}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c3154f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ds = tf.data.Dataset.from_tensor_slices(titanic_features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c00cdd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                : b'male'\n",
      "age                : 22.0\n",
      "n_siblings_spouses : 1\n",
      "parch              : 0\n",
      "fare               : 7.25\n",
      "class              : b'Third'\n",
      "deck               : b'unknown'\n",
      "embark_town        : b'Southampton'\n",
      "alone              : b'n'\n"
     ]
    }
   ],
   "source": [
    "for example in features_ds:\n",
    "    for name, value in example.items():\n",
    "        print(f\"{name:19}: {value}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31bec099",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_ds = tf.data.Dataset.from_tensor_slices((titanic_features_dict, titanic_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2131649",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_batchs = titanic_ds.shuffle(len(titanic_ds)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8c3a512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4231\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4226\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4210\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4224\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b853445640>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_model.fit(titanic_batchs, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54477b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_file_path = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "# titanic_file_path = tf.keras.utils.get_file('train.csv', path + 'titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1778ee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_csv_ds = tf.data.experimental.make_csv_dataset(titanic_file_path,\n",
    "                                                      batch_size=3,\n",
    "                                                      label_name='survived',\n",
    "                                                      num_epochs=1,\n",
    "                                                      ignore_errors=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3a5159d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(OrderedDict([('sex', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('age', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('n_siblings_spouses', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('parch', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('fare', TensorSpec(shape=(None,), dtype=tf.float32, name=None)), ('class', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('deck', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('embark_town', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('alone', TensorSpec(shape=(None,), dtype=tf.string, name=None))]), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_csv_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ba1681e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                 : [b'male' b'female' b'female']\n",
      "age                 : [28.5 24.   4. ]\n",
      "n_siblings_spouses  : [0 0 0]\n",
      "parch               : [0 0 1]\n",
      "fare                : [ 7.229 13.    13.417]\n",
      "class               : [b'Third' b'Second' b'Third']\n",
      "deck                : [b'unknown' b'unknown' b'unknown']\n",
      "embark_town         : [b'Cherbourg' b'Southampton' b'Cherbourg']\n",
      "alone               : [b'y' b'y' b'n']\n",
      "\n",
      "label               : [0 0 1]\n"
     ]
    }
   ],
   "source": [
    "for batch, label in titanic_csv_ds.take(1):\n",
    "    for key, value in batch.items():\n",
    "        print(f\"{key:20}: {value}\")\n",
    "    print()\n",
    "    print(f\"{'label':20}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2de728d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_volume_csv_gz = tf.keras.utils.get_file(\n",
    "    'Metro_Interstate_Traffic_Volume.csv.gz', \n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz\",\n",
    "    cache_dir='.', cache_subdir='traffic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e1ccb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holiday             , [b'None' b'None' b'None' b'None' b'None']\n",
      "temp                , [270.48 269.11 266.39 291.72 271.27]\n",
      "rain_1h             , [0. 0. 0. 0. 0.]\n",
      "snow_1h             , [0. 0. 0. 0. 0.]\n",
      "clouds_all          , [ 1 90  1  1 90]\n",
      "weather_main        , [b'Clear' b'Clouds' b'Clear' b'Clear' b'Clouds']\n",
      "weather_description , [b'sky is clear' b'overcast clouds' b'sky is clear' b'sky is clear'\n",
      " b'overcast clouds']\n",
      "date_time           , [b'2013-03-23 22:00:00' b'2013-02-09 02:00:00' b'2013-04-04 05:00:00'\n",
      " b'2012-10-02 14:00:00' b'2013-01-20 04:00:00']\n",
      "label               , [4260  525 2605 5181  246]\n"
     ]
    }
   ],
   "source": [
    "traffic_volume_csv_gz_ds = tf.data.experimental.make_csv_dataset(traffic_volume_csv_gz,\n",
    "                                                                batch_size=256,\n",
    "                                                                label_name='traffic_volume',\n",
    "                                                                num_epochs=1,\n",
    "                                                                compression_type='GZIP')\n",
    "\n",
    "for batch, label in traffic_volume_csv_gz_ds.take(1):\n",
    "    for key, value in batch.items():\n",
    "        print(f\"{key:20}, {value[:5]}\")\n",
    "    print(f\"{'label':20}, {label[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fd2409",
   "metadata": {},
   "source": [
    "###### Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc9ed40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................\n",
      "CPU times: total: 8.19 s\n",
      "Wall time: 5.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, (batch, label) in enumerate(traffic_volume_csv_gz_ds.repeat(20)):\n",
    "    if i % 40 == 0:\n",
    "        print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5239fadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................\n",
      "CPU times: total: 891 ms\n",
      "Wall time: 672 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "caching = traffic_volume_csv_gz_ds.cache().shuffle(1000)\n",
    "\n",
    "for i, (batch, label) in enumerate(caching.shuffle(1000).repeat(20)):\n",
    "    if i % 40 == 0:\n",
    "        print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ecbc7a57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <timed exec>:1: snapshot (from tensorflow.python.data.experimental.ops.snapshot) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.snapshot(...)`.\n",
      "...............................................................................................\n",
      "CPU times: total: 1.5 s\n",
      "Wall time: 964 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "snapshot = tf.data.experimental.snapshot('titanic.tfsnap')\n",
    "snapshotting = traffic_volume_csv_gz_ds.apply(snapshot).shuffle(1000)\n",
    "\n",
    "for i, (batch, label) in enumerate(snapshotting.shuffle(1000).repeat(20)):\n",
    "    if i % 40 == 0:\n",
    "        print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edc8e77",
   "metadata": {},
   "source": [
    "###### Multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a1303a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts_zip = tf.keras.utils.get_file(\n",
    "    'fonts.zip',  \"https://archive.ics.uci.edu/ml/machine-learning-databases/00417/fonts.zip\",\n",
    "    cache_dir='.', cache_subdir='fonts',\n",
    "    extract=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb6c432b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fonts\\\\AGENCY.csv',\n",
       " 'fonts\\\\ARIAL.csv',\n",
       " 'fonts\\\\BAITI.csv',\n",
       " 'fonts\\\\BANKGOTHIC.csv',\n",
       " 'fonts\\\\BASKERVILLE.csv',\n",
       " 'fonts\\\\BAUHAUS.csv',\n",
       " 'fonts\\\\BELL.csv',\n",
       " 'fonts\\\\BERLIN.csv',\n",
       " 'fonts\\\\BERNARD.csv',\n",
       " 'fonts\\\\BITSTREAMVERA.csv']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "font_csvs = sorted(str(p) for p in pathlib.Path('fonts').glob('*.csv'))\n",
    "font_csvs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d50b8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(font_csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a37b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts_ds = tf.data.experimental.make_csv_dataset(file_pattern = \"fonts/*.csv\",\n",
    "                                                batch_size=10, num_epochs=1,\n",
    "                                                num_parallel_reads=20,\n",
    "                                                 shuffle=False,\n",
    "                                                shuffle_buffer_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "505aac14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "font                : [b'AGENCY' b'ARIAL' b'BAITI' b'BANKGOTHIC' b'BASKERVILLE' b'BAUHAUS'\n",
      " b'BELL' b'BERLIN' b'BERNARD' b'BITSTREAMVERA']\n",
      "fontVariant         : [b'AGENCY FB' b'scanned' b'MONGOLIAN BAITI' b'BANKGOTHIC MD BT'\n",
      " b'BASKERVILLE OLD FACE' b'BAUHAUS 93' b'BELL MT' b'BERLIN SANS FB DEMI'\n",
      " b'BERNARD MT CONDENSED' b'scanned']\n",
      "m_label             : [64258    48 65311 61442 61442 61442 61442 64258 61442    74]\n",
      "strength            : [0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4]\n",
      "italic              : [0 0 0 0 0 0 0 0 0 0]\n",
      "orientation         : [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "m_top               : [35  0 32 46 33 35 33 34 33  0]\n",
      "m_left              : [21  0 36 26 21 24 23 21 21  0]\n",
      "originalH           : [51 15 46 28 46 45 45 48 53 20]\n",
      "originalW           : [22 25 24 66 34 30 31 39 31 36]\n",
      "h                   : [20 20 20 20 20 20 20 20 20 20]\n",
      "w                   : [20 20 20 20 20 20 20 20 20 20]\n",
      "r0c0                : [  1   1   1 255   1   1   1   1   1   1]\n",
      "r0c1                : [  1   1   1 255   1   1   1   1   1   1]\n",
      "r0c2                : [  1   1   1 255   1   1   1   1   1   1]\n",
      "r0c3                : [ 21   1  23 255   1   1   1   1   9   1]\n",
      "...\n",
      "[total: 412 features]\n"
     ]
    }
   ],
   "source": [
    "for features in fonts_ds.take(1):\n",
    "    for i, (name, value) in enumerate(features.items()):\n",
    "        if i > 15:\n",
    "            break\n",
    "        print(f\"{name:20}: {value}\")\n",
    "print('...')\n",
    "print(f\"[total: {len(features)} features]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e89eeeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "temp = 0\n",
    "def make_images(features):\n",
    "    image = [None] * 400\n",
    "    new_feats = {}\n",
    "    \n",
    "    for name, value in features.items():\n",
    "        match = re.match('r(\\d+)c(\\d+)', name)\n",
    "        if match:\n",
    "            image[int(match.group(1)) * 20 + int(match.group(2))] = value\n",
    "        else:\n",
    "            new_feats[name] = value\n",
    "            \n",
    "    image = tf.stack(image, axis=0)\n",
    "    image = tf.reshape(image, [20, 20, -1])\n",
    "    new_feats['image'] = image\n",
    "    \n",
    "    return new_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "88a79d88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fonts_image_ds = fonts_ds.map(make_images)\n",
    "\n",
    "for features in fonts_image_ds.take(1):\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db967baf",
   "metadata": {},
   "source": [
    "아래 표현 중 ['image'][..., n] 이건 뭐? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "626171bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\winston\\anaconda3_64\\envs\\tf25\\lib\\site-packages\\IPython\\core\\pylabtools.py:151: UserWarning: Glyph 65311 (\\N{FULLWIDTH QUESTION MARK}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 6), dpi=120)\n",
    "\n",
    "for n in range(9):\n",
    "    plt.subplot(3, 3, n + 1)\n",
    "    plt.imshow(features['image'][..., n])\n",
    "    plt.title(chr(features['m_label'][n]))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ae4c27",
   "metadata": {},
   "source": [
    "###### Lower Level functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "956808c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = pathlib.Path(titanic_file_path).read_text()\n",
    "lines = text.split('\\n')[1:-1]\n",
    "\n",
    "all_strings = [str()] * 10\n",
    "all_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "82965e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n"
     ]
    }
   ],
   "source": [
    "features = tf.io.decode_csv(lines, record_defaults=all_strings)\n",
    "\n",
    "for f in features:\n",
    "    print(f\"type: {f.dtype.name}, shape: {f.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c3c5c334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,male,22.0,1,0,7.25,Third,unknown,Southampton,n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7a43f9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 male\n",
      "2 22.0\n",
      "3 1\n",
      "4 0\n",
      "5 7.25\n",
      "6 Third\n",
      "7 unknown\n",
      "8 Southampton\n",
      "9 n\n"
     ]
    }
   ],
   "source": [
    "for i, t in enumerate(lines[0].split(',')):\n",
    "    print(i, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6affa971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, '', 0.0, 0, 0, 0.0, '', '', '', '']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_types = [int(), str(), float(), int(), int(), float(), str(), str(), str(), str()]\n",
    "titanic_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1652d3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: int32, shpae: (627,)\n",
      "type: string, shpae: (627,)\n",
      "type: float32, shpae: (627,)\n",
      "type: int32, shpae: (627,)\n",
      "type: int32, shpae: (627,)\n",
      "type: float32, shpae: (627,)\n",
      "type: string, shpae: (627,)\n",
      "type: string, shpae: (627,)\n",
      "type: string, shpae: (627,)\n",
      "type: string, shpae: (627,)\n"
     ]
    }
   ],
   "source": [
    "features = tf.io.decode_csv(lines, record_defaults=titanic_types)\n",
    "\n",
    "for f in features:\n",
    "#     print(f)\n",
    "    print(f\"type: {f.dtype.name}, shpae: {f.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8a839fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "094da683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, b'male', 22.0, 1, 0, 7.25, b'Third', b'unknown', b'Southampton', b'n']\n"
     ]
    }
   ],
   "source": [
    "simple_titanic = tf.data.experimental.CsvDataset(titanic_file_path,\n",
    "                                                 record_defaults=titanic_types,\n",
    "                                                header=True)\n",
    "for example in simple_titanic.take(1):\n",
    "    print([e.numpy() for e in example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d2866407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.experimental.ops.readers.CsvDatasetV2"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(simple_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "87f8145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_titanic_line(line):\n",
    "    return tf.io.decode_csv(line, titanic_types)\n",
    "\n",
    "manual_titanic = (\n",
    "    # Load the lines of text\n",
    "    tf.data.TextLineDataset(titanic_file_path)\n",
    "    # Skip the header row\n",
    "    .skip(1)\n",
    "    # Decode the line\n",
    "    .map(decode_titanic_line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "50211047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, b'male', 22.0, 1, 0, 7.25, b'Third', b'unknown', b'Southampton', b'n']\n"
     ]
    }
   ],
   "source": [
    "for example in manual_titanic.take(1):\n",
    "    print([e.numpy() for e in example])\n",
    "#     print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424d1508",
   "metadata": {},
   "source": [
    "###### Multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "78fcfbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGENCY,AGENCY FB,64258,0.400000,0,0.000000,35,21,51,22,20,20,1,1,1,21,101,210,255,255,255,255,255,255,255,255,255,255,255,255,255,255,1,1,1,93,255,255,255,176,146,146,146,146,146,146,146,146,216,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,141,141,141,182,255,255,255,172,141,141,141,115,1,1,1,1,163,255,255,255,255,255,255,255,255,255,255,255,255,255,255,209,1,1,1,1,163,255,255,255,6,6,6,96,255,255,255,74,6,6,6,5,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255\n"
     ]
    }
   ],
   "source": [
    "font_line = pathlib.Path(font_csvs[0]).read_text().splitlines()[1]\n",
    "print(font_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c10e5f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_font_features = len(font_line.split(','))\n",
    "font_column_types = [str(), str()] + [float()] * (num_font_features - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cb9748b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fonts\\\\AGENCY.csv'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "font_csvs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eaad5d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_font_ds = tf.data.experimental.CsvDataset(\n",
    "    font_csvs, record_defaults=font_column_types, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "69f644df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n"
     ]
    }
   ],
   "source": [
    "for row in simple_font_ds.take(10):\n",
    "    print(row[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "806b19e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "font_files = tf.data.Dataset.list_files('fonts/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d3c7c1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "       b'fonts\\\\TAHOMA.csv'\n",
      "       b'fonts\\\\HAETTENSCHWEILER.csv'\n",
      "       b'fonts\\\\EBRIMA.csv'\n",
      "       b'fonts\\\\TEMPUS.csv'\n",
      "       b'fonts\\\\COUNTRYBLUEPRINT.csv'\n",
      "      ...\n",
      "\n",
      "Epoch 2:\n",
      "       b'fonts\\\\TAI.csv'\n",
      "       b'fonts\\\\PHAGSPA.csv'\n",
      "       b'fonts\\\\MODERN.csv'\n",
      "       b'fonts\\\\HARRINGTON.csv'\n",
      "       b'fonts\\\\MISTRAL.csv'\n",
      "      ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Epoch 1:')\n",
    "for f in list(font_files)[:5]:\n",
    "    print(\"      \", f.numpy())\n",
    "print('      ...')\n",
    "print()\n",
    "\n",
    "print('Epoch 2:')\n",
    "for f in list(font_files)[:5]:\n",
    "    print(\"      \", f.numpy())\n",
    "print('      ...')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "87203a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_font_csv_ds(path):\n",
    "    return tf.data.experimental.CsvDataset(\n",
    "        path, record_defaults=font_column_types, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b8b282f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "font_rows = font_files.interleave(make_font_csv_ds, cycle_length=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6e60f71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\winston\\AppData\\Local\\Temp\\ipykernel_15272\\131471618.py:6: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  fonts_dict['charactor'].append(chr(row[2].numpy()))\n"
     ]
    }
   ],
   "source": [
    "fonts_dict = {'font_name': [], 'charactor': []}\n",
    "temp = font_rows.take(10)\n",
    "\n",
    "for row in temp:\n",
    "    fonts_dict['font_name'].append(row[0].numpy())\n",
    "    fonts_dict['charactor'].append(chr(row[2].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3a47799f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>font_name</th>\n",
       "      <th>charactor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'SNAP'</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'FRANKLIN'</td>\n",
       "      <td>ﬂ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'COURIER'</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'SNAP'</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'FRANKLIN'</td>\n",
       "      <td>ﬁ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b'COURIER'</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b'SNAP'</td>\n",
       "      <td>◊</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b'FRANKLIN'</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b'COURIER'</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b'SNAP'</td>\n",
       "      <td>≥</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     font_name charactor\n",
       "0      b'SNAP'         \n",
       "1  b'FRANKLIN'         ﬂ\n",
       "2   b'COURIER'         *\n",
       "3      b'SNAP'         \n",
       "4  b'FRANKLIN'         ﬁ\n",
       "5   b'COURIER'         0\n",
       "6      b'SNAP'         ◊\n",
       "7  b'FRANKLIN'         \n",
       "8   b'COURIER'         3\n",
       "9      b'SNAP'         ≥"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(fonts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10845a87",
   "metadata": {},
   "source": [
    "###### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "211fbacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2048\n",
    "fonts_ds = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern = 'fonts/*.csv', batch_size=BATCH_SIZE, \n",
    "    num_epochs=1,num_parallel_reads=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bb16bad5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, \n",
      "CPU times: total: 24.2 s\n",
      "Wall time: 7.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, batch in enumerate(fonts_ds.take(20)):\n",
    "    print(i, end=', ')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "21f26683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'category_encoding_4')>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eaecf3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts_files = tf.data.Dataset.list_files(\"fonts/*.csv\")\n",
    "fonts_lines = fonts_files.interleave(\n",
    "    lambda fname:tf.data.TextLineDataset(fname).skip(1), \n",
    "    cycle_length=100).batch(BATCH_SIZE)\n",
    "\n",
    "fonts_fast = fonts_lines.map(lambda y: tf.io.decode_csv(y, record_defaults=font_column_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d4b4bd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, \n",
      "CPU times: total: 3.62 s\n",
      "Wall time: 587 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, batch in enumerate(fonts_fast.take(20)):\n",
    "    print(i, end=', ')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "16920d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'category_encoding_4')>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05bb1ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75ba7c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d507e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ff91f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbfd1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fe86c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a293fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c64236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee0f70d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01122d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d302ff43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b7a4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370540f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b298e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c828c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e581aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9f7668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf25",
   "language": "python",
   "name": "tf25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
